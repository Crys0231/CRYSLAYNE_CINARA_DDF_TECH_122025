# Projeto â€“ Plataforma de Dados para CatÃ¡logo TÃ©cnico de Rolamentos

## VisÃ£o Geral

Este projeto Ã© uma **Prova de Conceito (PoC)** de uma Plataforma de Dados construÃ­da para um cenÃ¡rio de **e-commerce industrial**, com foco em **catÃ¡logo tÃ©cnico de rolamentos**, **vendas** e **suporte Ã  decisÃ£o tÃ©cnica e comercial**.

A soluÃ§Ã£o demonstra como dados estruturados e desestruturados podem ser integrados, tratados, analisados e explorados utilizando a **plataforma Dadosfera**, com apoio de **Machine Learning** e **GenAI**, para acelerar o caminho entre **dados tÃ©cnicos complexos** e **valor de negÃ³cio**.

O projeto foi desenvolvido como parte de um **case tÃ©cnico**, seguindo as melhores prÃ¡ticas do ciclo de vida dos dados: integraÃ§Ã£o, exploraÃ§Ã£o, qualidade, processamento, anÃ¡lise, pipelines e entrega via Data App.

---

## Objetivo do Projeto

O principal objetivo Ã© criar uma plataforma capaz de:

* Centralizar dados de catÃ¡logo tÃ©cnico, vendas e clientes
* Transformar descriÃ§Ãµes tÃ©cnicas em **features analÃ­ticas** utilizando LLMs
* Permitir que usuÃ¡rios descrevam **problemas industriais em linguagem natural**
* Recomendar produtos adequados com base em similaridade tÃ©cnica
* Comparar **custo x oportunidade** para apoiar decisÃµes de compra

---

## Escopo da SoluÃ§Ã£o

### Dentro do escopo

* CatÃ¡logo tÃ©cnico de rolamentos
* HistÃ³rico de vendas
* Perfil de clientes industriais
* Feature engineering com LLM
* Similaridade entre produtos
* AnÃ¡lises descritivas e temporais
* Data App interativo com Streamlit

### Fora do escopo

* AnÃ¡lises geogrÃ¡ficas no Data App
* Processamento de dados em tempo real
* IntegraÃ§Ãµes com sistemas externos de produÃ§Ã£o

---

## Arquitetura de Dados

A arquitetura segue o padrÃ£o recomendado pela Dadosfera, organizada em camadas:

* **Raw**: dados brutos no formato original
* **Trusted**: dados tratados e validados
* **Refined**: dados modelados para consumo analÃ­tico

A modelagem segue o padrÃ£o **Dimensional (Kimball)**, com tabelas fato e dimensÃµes otimizadas para BI, ML e Data Apps.

Detalhes completos podem ser encontrados em:

* [`arquitetura.md`](docs/arquitetura.md)
* [`modelagem_dados.md`](docs/modelagem_dados.md)

---

## Estrutura do RepositÃ³rio

```
ğŸ“¦ SEU_REPO
 â”£ ğŸ“‚ data
 â”ƒ â”£ ğŸ“‚ raw
 â”ƒ â”£ ğŸ“‚ trusted
 â”ƒ â”— ğŸ“‚ refined
 â”£ ğŸ“‚ notebooks
 â”ƒ â”£ 01_data_generation.ipynb
 â”ƒ â”£ 02_data_quality.ipynb
 â”ƒ â”£ 03_llm_feature_engineering.ipynb
 â”ƒ â”£ 04_eda_analysis.ipynb
 â”ƒ â”— 05_ml_similarity.ipynb
 â”£ ğŸ“‚ pipelines
 â”ƒ â”— pipeline_etl.md
 â”£ ğŸ“‚ data_app
 â”ƒ â”— app.py
 â”£ ğŸ“‚ docs
 â”ƒ â”£ arquitetura.md
 â”ƒ â”£ modelagem_dados.md
 â”ƒ â”— planejamento.md
 â”— README.md
```

---

## Dataset

Os dados utilizados representam um cenÃ¡rio realista de e-commerce industrial e foram **gerados sinteticamente** para fins educacionais.

CaracterÃ­sticas:

* Mais de **100.000 registros**
* Dados estruturados (vendas, clientes)
* Dados semiestruturados e textuais (catÃ¡logo tÃ©cnico)

Scripts e notebooks de geraÃ§Ã£o estÃ£o disponÃ­veis em:

* `01_data_generation.ipynb`

---

## Machine Learning e GenAI

O projeto utiliza tÃ©cnicas de ML e GenAI para:

* ExtraÃ§Ã£o de features tÃ©cnicas a partir de descriÃ§Ãµes textuais
* CriaÃ§Ã£o de embeddings para produtos
* CÃ¡lculo de similaridade semÃ¢ntica
* Matching entre problemas descritos pelo usuÃ¡rio e produtos do catÃ¡logo

Essas etapas estÃ£o documentadas nos notebooks:

* `03_llm_feature_engineering.ipynb`
* `05_ml_similarity.ipynb`

---

## Data App

O Data App foi desenvolvido com **Streamlit** e tem como objetivo:

* Receber descriÃ§Ãµes de problemas tÃ©cnicos em linguagem natural
* Analisar produtos disponÃ­veis no catÃ¡logo
* Apresentar recomendaÃ§Ãµes tÃ©cnicas
* Comparar custo e oportunidade entre soluÃ§Ãµes

### ExecuÃ§Ã£o local

```bash
streamlit run data_app/app.py
```

Opcionalmente, o app pode ser publicado no **Streamlit Community Cloud**.

---

## Pipelines de Dados

O projeto inclui um pipeline de dados que contempla:

* ETL das camadas Raw â†’ Trusted â†’ Refined
* ValidaÃ§Ãµes de qualidade de dados
* PreparaÃ§Ã£o de dados para ML

A documentaÃ§Ã£o do pipeline estÃ¡ disponÃ­vel em:

* `pipelines/pipeline_etl.md`

---

## Planejamento e Metodologia

O projeto foi planejado seguindo boas prÃ¡ticas de gestÃ£o, com foco em:

* Entregas incrementais
* Clareza de escopo
* Reprodutibilidade

O planejamento detalhado pode ser encontrado em:

* `docs/planejamento.md`

---

## Resultados Esperados

* Plataforma analÃ­tica funcional ponta a ponta
* DemonstraÃ§Ã£o clara do ciclo de vida dos dados
* AplicaÃ§Ã£o prÃ¡tica de IA em dados industriais
* Base escalÃ¡vel para evoluÃ§Ãµes futuras

---

## EvoluÃ§Ãµes Futuras

* InclusÃ£o de dados de manutenÃ§Ã£o e falhas
* Modelos preditivos de falha de rolamentos
* IntegraÃ§Ã£o com dados IoT
* ExpansÃ£o do Data App para novos casos de uso

---

## ConsideraÃ§Ãµes Finais

Este projeto demonstra como a **Dadosfera** pode ser utilizada como uma soluÃ§Ã£o completa para centralizar dados, aplicar inteligÃªncia artificial e entregar valor de forma Ã¡gil, mesmo em domÃ­nios tÃ©cnicos complexos como o industrial.

Ele serve como uma prova de conceito de que Ã© possÃ­vel transformar dados tÃ©cnicos em **insights acionÃ¡veis**, apoiando decisÃµes estratÃ©gicas e operacionais.
